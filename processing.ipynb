{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "def excel_reader():\n",
    "    # 해당 경로에 있는 .xlsx 포맷의 파일이름을 리스트로 가져오기\n",
    "    path = \"/home/u1026/tm_2020/\"\n",
    "    file_list = os.listdir(path)\n",
    "    exfile_list = [i for i in file_list if os.path.splitext(i)[-1] == \".xlsx\"]\n",
    "\n",
    "    # 파일이름을 split 해 해당 파일의 날짜 리스트로 가져오기\n",
    "    fname_list = []\n",
    "    for i in range(len(exfile_list)):\n",
    "        fname_list += [exfile_list[i].split(\"-\")[0].split(\"_\")[1]]\n",
    "\n",
    "    # exfile_list에 있는 엑셀파일 모두 읽어오기\n",
    "    for k in range(len(exfile_list)):\n",
    "        file_locate = path + exfile_list[k]\n",
    "        setattr(mod, 'file_{}'.format(fname_list[k]), pd.read_excel(file_locate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#file_20200801.head()\n",
    "#file_20200802.head()\n",
    "file_20200802['제목'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5613 entries, 0 to 5612\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   뉴스 식별자             5611 non-null   float64\n",
      " 1   일자                 5611 non-null   float64\n",
      " 2   언론사                5611 non-null   object \n",
      " 3   기고자                5433 non-null   object \n",
      " 4   제목                 5611 non-null   object \n",
      " 5   통합 분류1             5613 non-null   object \n",
      " 6   통합 분류2             4668 non-null   object \n",
      " 7   통합 분류3             3861 non-null   object \n",
      " 8   사건/사고 분류1          973 non-null    object \n",
      " 9   사건/사고 분류2          342 non-null    object \n",
      " 10  사건/사고 분류3          113 non-null    object \n",
      " 11  인물                 3065 non-null   object \n",
      " 12  위치                 4972 non-null   object \n",
      " 13  기관                 5202 non-null   object \n",
      " 14  키워드                5610 non-null   object \n",
      " 15  특성추출(가중치순 상위 50개)  5610 non-null   object \n",
      " 16  본문                 5611 non-null   object \n",
      " 17  URL                5611 non-null   object \n",
      " 18  분석제외 여부            407 non-null    object \n",
      "dtypes: float64(2), object(17)\n",
      "memory usage: 833.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#file_20200801.info()\n",
    "file_20200802.info()\n",
    "#news_20200802['제목']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns_name = ['일자', '제목', '본문', '인물', '기관', '키워드', '특성추출(가중치순 상위 50개)', 'URL']\n",
    "file_20200801 = file_20200801[columns_name]\n",
    "file_20200802 = file_20200802[columns_name]\n",
    "\n",
    "news_20200801 = file_20200801\n",
    "news_20200802 = file_20200802\n",
    "\n",
    "#'제목'열에서 na가 있으면 해당 행 삭제\n",
    "news_20200801 = news_20200801.dropna(subset = ['제목'])\n",
    "news_20200802 = news_20200802.dropna(subset = ['제목'])\n",
    "\n",
    "#row번호 리셋하기\n",
    "news_20200801 = news_20200801.reset_index()\n",
    "news_20200802 = news_20200802.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u1026/.local/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/u1026/.local/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#제목 마지막에 공백을 넣어 본문과 합칠 때 자연스럽게 합치게 함\n",
    "for i in range(0,len(news_20200801)):\n",
    "    news_20200801['제목'][i] = news_20200801['제목'][i] + ' '\n",
    "    \n",
    "for i in range(0,len(news_20200802)):\n",
    "    news_20200802['제목'][i] = news_20200802['제목'][i] + ' '\n",
    "\n",
    "\n",
    "news_20200801['내용'] = news_20200801.iloc[:, 2:4].sum(1)\n",
    "news_20200802['내용'] = news_20200802.iloc[:, 2:4].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WHO 긴급위, 국제적 비상사태 유지키로 \"코로나 장기화 예상\" '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_20200802['제목'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u1026/.local/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/u1026/.local/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(news_20200801)):\n",
    "    news_20200801['내용'][i] = news_20200801['내용'][i].replace(',','').replace('\\n','').replace('.','').replace('\"','').replace('!','').replace('(',' ').replace(')','').replace('?','').casefold()\n",
    "    #print(news_20200801['내용'][i])\n",
    "\n",
    "for i in range(0,len(news_20200802)):\n",
    "    news_20200802['내용'][i] = news_20200802['내용'][i].replace(',','').replace('\\n','').replace('.','').replace('\"','').replace('!','').replace('(',' ').replace(')','').replace('?','').casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_tokenize : space 단위와 구두점(punctuation)을 기준으로 토큰화(Tokenize)\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_20200801 =[]\n",
    "for i in range(len(news_20200801)):\n",
    "    word_20200801 += (word_20200801, word_tokenize(news_20200801['내용'][i]))\n",
    "    #print(word_tokenize(news_190801['내용'][i]))\n",
    "\n",
    "#. 기준으로 문장쪼개기\n",
    "sentence_20200801 = []\n",
    "for i in range(len(news_20200801)):\n",
    "    sentence_20200801 += (sentence_20200801, news_20200801['내용'][i].split(\".\"))\n",
    "#print(news_190801['내용'][i].split(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "okt.morphs  # 형태소 분석\n",
    "okt.nouns  # 명사 분석\n",
    "okt.phrases  # 구(Phrase) 분석\n",
    "okt.pos  # 형태소 분석 태깅\n",
    "\n",
    "okt_word_20200801 = []\n",
    "for i in range(len(news_20200801)):\n",
    "    #print(okt.morphs(news_190801['내용'][i]))\n",
    "    okt_word_20200801 +=  okt.morphs(news_20200801['내용'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['모츠',\n",
       " 'motz',\n",
       " '비대',\n",
       " '면',\n",
       " '라이브',\n",
       " '이벤트',\n",
       " '솔루션',\n",
       " '출시',\n",
       " '지금',\n",
       " '까지와',\n",
       " '는',\n",
       " '전혀',\n",
       " '다른',\n",
       " '언택트',\n",
       " '시대',\n",
       " '가',\n",
       " '다가오면서',\n",
       " '마케팅',\n",
       " '업계',\n",
       " '에도']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.utils import pprint\n",
    "\n",
    "#pprint(okt_word)\n",
    "okt_word_20200801[:20]\n",
    "#print(okt.pos(news_190801['내용'], norm=True, stem=True)) # norm=True 이면, 토큰 노멀라이즈, stem=True 이면, 토큰 스테밍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "#메모리 늘려주기\n",
    "komoran = Komoran(max_heap_size = 1024 * 6)\n",
    "\n",
    "km_word_20200801 = []\n",
    "for i in range(len(news_20200801)):\n",
    "    #print(okt.morphs(news_190801['내용'][i]))\n",
    "    km_word_20200801 +=  komoran.nouns(news_20200801['내용'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['비대', '라이브', '이벤트', '솔루션', '출시', '지금', '언', '택', '시대', '마케팅']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.utils import pprint\n",
    "\n",
    "km_word_20200801[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675\n",
      "775\n",
      "664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['거바',\n",
       " '제',\n",
       " '하더라도',\n",
       " '사람',\n",
       " '까지',\n",
       " '어떤',\n",
       " '견지에서',\n",
       " '하기는한데',\n",
       " '해도좋다',\n",
       " '예를 들자면',\n",
       " '보다더',\n",
       " '게우다',\n",
       " '어때',\n",
       " '도착하다',\n",
       " '이와 같다',\n",
       " '륙',\n",
       " '말하자면',\n",
       " '옆사람',\n",
       " '그런',\n",
       " '인 듯하다']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = []\n",
    "with open('./data_files/stopwords_list1.txt', 'r') as file1, \\\n",
    "open('./data_files/stopwords_list2.txt', 'r') as file2:\n",
    "    for text1 in file1:\n",
    "        stop_words.append(text1.strip('\\n'))\n",
    "    print(len(stop_words))\n",
    "    for text2_1 in file2:\n",
    "        text2 = text2_1.split('\\t')\n",
    "        stop_words.append(text2[0].strip('\\n'))\n",
    "    print(len(stop_words))\n",
    "\n",
    "\n",
    "stopwords_set = set(stop_words)\n",
    "stop_words = list(stopwords_set)\n",
    "\n",
    "#중복된 stopwords 제거됨\n",
    "print(len(stop_words))\n",
    "stop_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['비대', '라이브', '이벤트', '솔루션', '출시', '언', '택', '시대', '마케팅', '업계']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#불용어 제거하기\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "\"\"\"\n",
    "#pos태그 사용할 때\n",
    "word_result_20200801 = []\n",
    "for w, t in okt_word_20200801:\n",
    "    if w not in stop_words:\n",
    "        word_result_20200801.append(w)\n",
    "# 위의 4줄은 아래의 한 줄로 대체 가능\n",
    "# result = [word for word in word_tokens if not word in stop_words]\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "#okt 사용할 때\n",
    "word_result_20200801 = []\n",
    "for w in okt_word_20200801:\n",
    "    if w not in stop_words:\n",
    "        word_result_20200801.append(w)\n",
    "\"\"\"\n",
    "\n",
    "#komoran 사용할 때\n",
    "word_result_20200801 = []\n",
    "for w in km_word_20200801:\n",
    "    if w not in stop_words:\n",
    "        word_result_20200801.append(w)\n",
    "\n",
    "#print(word_tokens) \n",
    "#print(word_result_20200801)\n",
    "word_result_20200801[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----불용어 제거 전----\n",
      "125969\n",
      "----불용어 제거 후----\n",
      "113056\n"
     ]
    }
   ],
   "source": [
    "print(\"----불용어 제거 전----\")\n",
    "print(len(km_word_20200801))\n",
    "print(\"----불용어 제거 후----\")\n",
    "print(len(word_result_20200801))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u1026/.local/lib/python3.7/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Twitter\n",
    "\n",
    "twitter = Twitter()\n",
    "\n",
    "twt_word = []\n",
    "for i in range(len(news_20200801)):\n",
    "    #print(okt.morphs(news_20200801['내용'][i]))\n",
    "    twt_word += twitter.pos(news_20200801['내용'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('모츠', 'Noun'),\n",
       " ('motz', 'Alpha'),\n",
       " ('비대', 'Noun'),\n",
       " ('면', 'Josa'),\n",
       " ('라이브', 'Noun'),\n",
       " ('이벤트', 'Noun'),\n",
       " ('솔루션', 'Noun'),\n",
       " ('출시', 'Noun'),\n",
       " ('지금', 'Noun'),\n",
       " ('까지와', 'Josa'),\n",
       " ('는', 'Verb'),\n",
       " ('전혀', 'Noun'),\n",
       " ('다른', 'Noun'),\n",
       " ('언택트', 'Noun'),\n",
       " ('시대', 'Noun'),\n",
       " ('가', 'Josa'),\n",
       " ('다가오면서', 'Verb'),\n",
       " ('마케팅', 'Noun'),\n",
       " ('업계', 'Noun'),\n",
       " ('에도', 'Josa')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twt_word[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113056\n",
      "12749\n"
     ]
    }
   ],
   "source": [
    "#vocabulary 만들기\n",
    "print(len(word_result_20200801))\n",
    "set_20200801 = set(word_result_20200801)\n",
    "voca_20200801 = list(set_20200801)\n",
    "print(len(voca_20200801))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 123)\t1\n",
      "  (1, 8907)\t1\n",
      "  (2, 994)\t1\n",
      "  (3, 5892)\t1\n",
      "  (4, 338)\t1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#뭐하는건진 모르겠는데 구글에서 찾음\n",
    "cv = CountVectorizer()\n",
    "tdm = cv.fit_transform(voca_20200801)\n",
    "print(tdm[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('비대', '라이브'),\n",
       " ('라이브', '이벤트'),\n",
       " ('이벤트', '솔루션'),\n",
       " ('솔루션', '출시'),\n",
       " ('출시', '언'),\n",
       " ('언', '택'),\n",
       " ('택', '시대'),\n",
       " ('시대', '마케팅'),\n",
       " ('마케팅', '업계'),\n",
       " ('업계', '변화')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#n-gram(bigram)\n",
    "bi_gram = list(zip(word_result_20200801, word_result_20200801[1:]))\n",
    "\n",
    "bi_gram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigram(input_list):\n",
    "    bi_gram = []\n",
    "    for i in range(0, len(input_list)-1):\n",
    "        bi_gram += [input_list[i] + ' ' + input_list[i+1]]\n",
    "    \n",
    "    return bi_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_gram = make_bigram(word_result_20200801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def find_ngrams(input_list, n):\n",
    "    #return zip(*[input_list[i:] for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#중복된 것 찾기\n",
    "def find_dup(ngram):\n",
    "    dup_not_list = list(set(ngram))\n",
    "    \n",
    "    dup_list = ngram\n",
    "    for v in dup_not_list:\n",
    "        dup_list.remove(v)\n",
    "    \n",
    "    return dup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "morethanonce = find_dup(bi_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('모츠', 'motz'),\n",
       " ('motz', '비대'),\n",
       " ('비대', '면'),\n",
       " ('면', '라이브'),\n",
       " ('라이브', '이벤트'),\n",
       " ('이벤트', '솔루션'),\n",
       " ('솔루션', '출시'),\n",
       " ('출시', '지금'),\n",
       " ('지금', '까지와'),\n",
       " ('까지와', '는')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#n-gram(bigram)\n",
    "bi_gram = list(zip(okt_word_20200801, okt_word_20200801[1:]))\n",
    "\n",
    "bi_gram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232767\n",
      "114141\n"
     ]
    }
   ],
   "source": [
    "print(len(bi_gram))\n",
    "#중복된 것 찾기\n",
    "print(len(list(set(bi_gram).intersection(bi_gram))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('면', '라이브'), ('모츠', 'motz'), ('motz', '비대'), ('라이브', '이벤트'), ('비대', '면')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(bi_gram[:5]).intersection(bi_gram[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('모츠', 'motz'), ('motz', '비대'), ('비대', '면'), ('면', '라이브'), ('라이브', '이벤트')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "dtm_ar_20200801 = cv.fit_transform(voca_20200801).toarray()\n",
    "feature_names = cv.get_feature_names()\n",
    "#dtm을 데이터프레임 형태로\n",
    "dtm_20200801 = pd.DataFrame(dtm_ar_20200801, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0시</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>100년</th>\n",
       "      <th>101</th>\n",
       "      <th>10년</th>\n",
       "      <th>10대</th>\n",
       "      <th>10분</th>\n",
       "      <th>10월</th>\n",
       "      <th>114</th>\n",
       "      <th>...</th>\n",
       "      <th>히브리</th>\n",
       "      <th>히스패닉</th>\n",
       "      <th>히어로</th>\n",
       "      <th>히터</th>\n",
       "      <th>힌두스탄</th>\n",
       "      <th>힌트</th>\n",
       "      <th>힐러리</th>\n",
       "      <th>힐링</th>\n",
       "      <th>힐스</th>\n",
       "      <th>힐스테이트</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0시  10  100  100년  101  10년  10대  10분  10월  114  ...  히브리  히스패닉  히어로  히터  \\\n",
       "0   0   0    0     0    0    0    0    0    0    0  ...    0     0    0   0   \n",
       "1   0   0    0     0    0    0    0    0    0    0  ...    0     0    0   0   \n",
       "2   0   0    0     0    0    0    0    0    0    0  ...    0     0    0   0   \n",
       "3   0   0    0     0    0    0    0    0    0    0  ...    0     0    0   0   \n",
       "4   0   0    0     0    0    0    0    0    0    0  ...    0     0    0   0   \n",
       "\n",
       "   힌두스탄  힌트  힐러리  힐링  힐스  힐스테이트  \n",
       "0     0   0    0   0   0      0  \n",
       "1     0   0    0   0   0      0  \n",
       "2     0   0    0   0   0      0  \n",
       "3     0   0    0   0   0      0  \n",
       "4     0   0    0   0   0      0  \n",
       "\n",
       "[5 rows x 12113 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_20200801.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-0',\n",
       " '-1',\n",
       " '-2',\n",
       " '-3',\n",
       " '-4',\n",
       " '-5',\n",
       " '0시',\n",
       " '10',\n",
       " '100',\n",
       " '100년',\n",
       " '101',\n",
       " '10년',\n",
       " '10년 후',\n",
       " '10대',\n",
       " '10분',\n",
       " '10월',\n",
       " '10월 1일',\n",
       " '10월 21일',\n",
       " '10월 30일',\n",
       " '10월 31일',\n",
       " '10월 4일',\n",
       " '114',\n",
       " '119',\n",
       " '11년',\n",
       " '11월',\n",
       " '11월 3일',\n",
       " '12',\n",
       " '12월',\n",
       " '12월 31일',\n",
       " '14']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voca_20200801[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 단어가 몇번째 인덱스에 존재하는지 확인\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
