{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import precleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "okt_word_20200801 = []\n",
    "for i in range(len(news_20200801)):\n",
    "    #print(okt.nouns(news_190801['내용'][i]))\n",
    "    okt_word_20200801 +=  okt.pos(news_20200801['제목'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt_nouns_20200801 = []\n",
    "for i in range(len(news_20200801)):\n",
    "    #print(okt.nouns(news_190801['내용'][i]))\n",
    "    okt_nouns_20200801 +=  okt.nouns(news_20200801['제목'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#j로 시작하는 tag들은 모두 조사 - i는 인덱스번호, k는 리스트의 요소\n",
    "for i, k in enumerate(okt_word_20200801):\n",
    "    #튜플인 k의 1번째 값(예-'JX')에 'J'가 첫번째 글자로 들어가 있으면 조사이므로 지운다.\n",
    "    if k[1].find('J') == 0 or k[1].find('P') or k[1].find('F') == 0:\n",
    "        okt_word_20200801.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "with open('../stopwordlist/stopwords_list1.txt', 'r') as file1, \\\n",
    "open('../stopwordlist/stopwords_list2.txt', 'r') as file2:\n",
    "    for text1 in file1:\n",
    "        stop_words.append(text1.strip('\\n'))\n",
    "    print(len(stop_words))\n",
    "    for text2_1 in file2:\n",
    "        text2 = text2_1.split('\\t')\n",
    "        stop_words.append(text2[0].strip('\\n'))\n",
    "    print(len(stop_words))\n",
    "\n",
    "#불용어리스트 생성\n",
    "stopwords_set = set(stop_words)\n",
    "stop_words = list(stopwords_set)\n",
    "\n",
    "\n",
    "#불용어 제거하기 - pos\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#okt-pos 사용\n",
    "word_result_20200801 = []\n",
    "for w, pos in okt_word_20200801:\n",
    "    if w not in stop_words:\n",
    "        word_result_20200801.append(w)\n",
    "\n",
    "print(\"----불용어 제거 전----\")\n",
    "print(len(okt_word_20200801))\n",
    "print(\"----불용어 제거 후----\")\n",
    "print(len(word_result_20200801))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 제거하기 - nouns\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#okt-nouns 사용\n",
    "nouns_result_20200801 = []\n",
    "for n in okt_nouns_20200801:\n",
    "    if n not in stop_words:\n",
    "        nouns_result_20200801.append(n)\n",
    "\n",
    "print(\"----불용어 제거 전----\")\n",
    "print(len(okt_nouns_20200801))\n",
    "print(\"----불용어 제거 후----\")\n",
    "print(len(nouns_result_20200801))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#한글자 지우기\n",
    "for i in word_result_20200801:\n",
    "    if len(i) == 1:\n",
    "        word_result_20200801.remove(i)\n",
    "        \n",
    "for i in nouns_result_20200801:\n",
    "    if len(i) == 1:\n",
    "        nouns_result_20200801.remove(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
